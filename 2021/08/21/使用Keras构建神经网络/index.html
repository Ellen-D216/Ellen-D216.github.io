<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ellen-d216.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Keras是个高级API，用它搭建神经网络很简单，适合入门。">
<meta property="og:type" content="article">
<meta property="og:title" content="使用Keras构建神经网络">
<meta property="og:url" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="Ellenの小站">
<meta property="og:description" content="Keras是个高级API，用它搭建神经网络很简单，适合入门。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_0.png">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_20_0.png">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_23_0.png">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_27_1.png">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_32_0.png">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_36_0.png">
<meta property="og:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_46_0.png">
<meta property="article:published_time" content="2021-08-21T04:46:27.000Z">
<meta property="article:modified_time" content="2021-08-21T05:21:48.183Z">
<meta property="article:author" content="Ellen DeGeneres">
<meta property="article:tag" content="Keras">
<meta property="article:tag" content="神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_0.png">

<link rel="canonical" href="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>使用Keras构建神经网络 | Ellenの小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Ellenの小站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录生活中的点点滴滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">4</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">0</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">3</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ellen-d216.github.io/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ellen DeGeneres">
      <meta itemprop="description" content="major in Nuclear Engineering and AI.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ellenの小站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          使用Keras构建神经网络
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-08-21 12:46:27 / 修改时间：13:21:48" itemprop="dateCreated datePublished" datetime="2021-08-21T12:46:27+08:00">2021-08-21</time>
            </span>

          
            <div class="post-description">Keras是个高级API，用它搭建神经网络很简单，适合入门。</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="使用顺序API构建图像分类器"><a href="#使用顺序API构建图像分类器" class="headerlink" title="使用顺序API构建图像分类器"></a>使用顺序API构建图像分类器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(X_train_full,y_train_full),(X_test,y_test) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train_full.shape,X_train_full.dtype</span><br></pre></td></tr></table></figure>
<pre><code>((60000, 28, 28), dtype(&#39;uint8&#39;))
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_valid, X_train = X_train_full[:<span class="number">5000</span>]/<span class="number">255.0</span>, X_train_full[<span class="number">5000</span>:]/<span class="number">255.0</span></span><br><span class="line">y_valid, y_train = y_train_full[:<span class="number">5000</span>], y_train_full[<span class="number">5000</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class_names = [<span class="string">&quot;T-shirt/top&quot;</span>, <span class="string">&quot;Trouser&quot;</span>, <span class="string">&quot;Pullover&quot;</span>, <span class="string">&quot;Dress&quot;</span>, <span class="string">&quot;Coat&quot;</span>, <span class="string">&quot;Sandal&quot;</span>, <span class="string">&quot;Shirt&quot;</span>, <span class="string">&quot;Sneaker&quot;</span>, <span class="string">&quot;Bag&quot;</span>, <span class="string">&quot;Ankle boot&quot;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(X_train[i],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.title(class_names[y_train[i]])</span><br></pre></td></tr></table></figure>
<img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_0.png" class="" alt="png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([keras.layers.Flatten(input_shape=[<span class="number">28</span>,<span class="number">28</span>]),</span><br><span class="line">                          keras.layers.Dense(<span class="number">300</span>,activation=keras.activations.relu),</span><br><span class="line">                          keras.layers.Dense(<span class="number">100</span>,activation=keras.activations.relu),</span><br><span class="line">                          keras.layers.Dense(<span class="number">10</span>,activation=keras.activations.softmax)])</span><br></pre></td></tr></table></figure>
<p>初始化时，对于每一层的权重和偏置可以使用<code>kernel_initializer</code>或<code>bias_initializer</code>进行初始化；\<br>权重矩阵的形状取决于输入的个数，我们应在第一层中指定<code>input_shape</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
dense (Dense)                (None, 300)               235500    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               30100     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1010      
=================================================================
Total params: 266,610
Trainable params: 266,610
Non-trainable params: 0
_________________________________________________________________
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.layers</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;keras.layers.core.Flatten at 0x294b10e2b50&gt;,
 &lt;keras.layers.core.Dense at 0x294b1182a90&gt;,
 &lt;keras.layers.core.Dense at 0x294b1141e20&gt;,
 &lt;keras.layers.core.Dense at 0x294b11817f0&gt;]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.layers[<span class="number">1</span>] == model.get_layer(<span class="string">&#x27;dense&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>True
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights, bias = model.layers[<span class="number">1</span>].get_weights()<span class="comment">#also has set_weights() or use kernel_initializer and bias_initializer</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights</span><br></pre></td></tr></table></figure>
<pre><code>array([[ 0.00432374,  0.069911  ,  0.04554318, ...,  0.02112412,
        -0.05035692, -0.04687664],
       [-0.02890603,  0.06612819,  0.05927478, ..., -0.04826843,
         0.00918571, -0.03757042],
       [-0.0468495 , -0.05732308,  0.00990029, ..., -0.00668625,
        -0.00170599,  0.01458585],
       ...,
       [-0.03658697, -0.03046996,  0.06218758, ...,  0.07221685,
        -0.03757465,  0.06432179],
       [ 0.02678267, -0.00753582,  0.02744661, ...,  0.07104121,
        -0.02597448,  0.04335685],
       [ 0.02518395,  0.05691384,  0.00831134, ..., -0.05676897,
         0.04779277, -0.06324223]], dtype=float32)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bias</span><br></pre></td></tr></table></figure>
<pre><code>array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=keras.losses.sparse_categorical_crossentropy,</span><br><span class="line">              optimizer=keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>),</span><br><span class="line">              metrics=keras.metrics.sparse_categorical_accuracy)</span><br></pre></td></tr></table></figure>
<p>注意：我们使用的损失函数如上所示，因为我们具有稀疏标签（即对于每个实例，只有一个目标类索引，例子情况下为0~9），并且这些类都是互斥的，\<br>若每个实例的每个类都有一个目标概率（独热编码），则我们要使用<code>categorical_crossentropy</code>。\<br>若我们正在执行二进制分类，输出层中应使用<code>sigmoid</code>激活函数，且使用<code>binary_crossentropy</code>损失。\<br>如果要将稀疏标签转换为独热向量，可以使用<code>keras.utils.to_categorical()</code>，反之则使用<code>np.argmax(axis=1)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(X_train,y_train,epochs=<span class="number">30</span>,validation_data=(X_valid,y_valid))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/30
1719/1719 [==============================] - 12s 5ms/step - loss: 0.7298 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.5163 - val_sparse_categorical_accuracy: 0.8270
Epoch 2/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.4473 - val_sparse_categorical_accuracy: 0.8508
Epoch 3/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.4459 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.4199 - val_sparse_categorical_accuracy: 0.8638
Epoch 4/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.4185 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.4072 - val_sparse_categorical_accuracy: 0.8606
Epoch 5/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3985 - sparse_categorical_accuracy: 0.8591 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.8636
Epoch 6/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3830 - sparse_categorical_accuracy: 0.8640 - val_loss: 0.3741 - val_sparse_categorical_accuracy: 0.8730
Epoch 7/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3692 - sparse_categorical_accuracy: 0.8692 - val_loss: 0.3805 - val_sparse_categorical_accuracy: 0.8696
Epoch 8/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3576 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.3639 - val_sparse_categorical_accuracy: 0.8738
Epoch 9/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3472 - sparse_categorical_accuracy: 0.8769 - val_loss: 0.3516 - val_sparse_categorical_accuracy: 0.8794
Epoch 10/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.8808 - val_loss: 0.3416 - val_sparse_categorical_accuracy: 0.8830
Epoch 11/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3295 - sparse_categorical_accuracy: 0.8828 - val_loss: 0.3500 - val_sparse_categorical_accuracy: 0.8788
Epoch 12/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.3198 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.3294 - val_sparse_categorical_accuracy: 0.8858
Epoch 13/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.3449 - val_sparse_categorical_accuracy: 0.8784
Epoch 14/30
1719/1719 [==============================] - 8s 4ms/step - loss: 0.3050 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.3874 - val_sparse_categorical_accuracy: 0.8580
Epoch 15/30
1719/1719 [==============================] - 8s 4ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.3280 - val_sparse_categorical_accuracy: 0.8854
Epoch 16/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2927 - sparse_categorical_accuracy: 0.8942 - val_loss: 0.3285 - val_sparse_categorical_accuracy: 0.8794
Epoch 17/30
1719/1719 [==============================] - 9s 5ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.3190 - val_sparse_categorical_accuracy: 0.8886
Epoch 18/30
1719/1719 [==============================] - 8s 4ms/step - loss: 0.2810 - sparse_categorical_accuracy: 0.8994 - val_loss: 0.3130 - val_sparse_categorical_accuracy: 0.8898
Epoch 19/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2751 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.3186 - val_sparse_categorical_accuracy: 0.8886
Epoch 20/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2702 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.3252 - val_sparse_categorical_accuracy: 0.8842
Epoch 21/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2643 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.3085 - val_sparse_categorical_accuracy: 0.8898
Epoch 22/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2609 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.3574 - val_sparse_categorical_accuracy: 0.8664
Epoch 23/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.2561 - sparse_categorical_accuracy: 0.9074 - val_loss: 0.3047 - val_sparse_categorical_accuracy: 0.8922
Epoch 24/30
1719/1719 [==============================] - 6s 4ms/step - loss: 0.2507 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.3185 - val_sparse_categorical_accuracy: 0.8862
Epoch 25/30
1719/1719 [==============================] - 8s 5ms/step - loss: 0.2471 - sparse_categorical_accuracy: 0.9112 - val_loss: 0.3100 - val_sparse_categorical_accuracy: 0.8896
Epoch 26/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2427 - sparse_categorical_accuracy: 0.9133 - val_loss: 0.3052 - val_sparse_categorical_accuracy: 0.8894
Epoch 27/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2396 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3033 - val_sparse_categorical_accuracy: 0.8934
Epoch 28/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2341 - sparse_categorical_accuracy: 0.9161 - val_loss: 0.3121 - val_sparse_categorical_accuracy: 0.8874
Epoch 29/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2310 - sparse_categorical_accuracy: 0.9171 - val_loss: 0.3057 - val_sparse_categorical_accuracy: 0.8888
Epoch 30/30
1719/1719 [==============================] - 7s 4ms/step - loss: 0.2272 - sparse_categorical_accuracy: 0.9190 - val_loss: 0.2938 - val_sparse_categorical_accuracy: 0.8928
</code></pre><p>我们可以设置<code>validation_split</code>指定用于验证的训练集的比例；\<br>如果训练集非常不平衡，某些类过多其他类不足，可以设置<code>class_weight</code>给代表性不足的类更大的权重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history.params</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;verbose&#39;: 1, &#39;epochs&#39;: 30, &#39;steps&#39;: 1719&#125;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(history.history).plot(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_20_0.png" class="" alt="png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(X_test,y_test,batch_size=<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>1/1 [==============================] - 0s 38ms/step - loss: 61.2780 - sparse_categorical_accuracy: 0.8535





[61.278011322021484, 0.8535000085830688]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_new = X_test[:<span class="number">3</span>]</span><br><span class="line">y_pred = model.predict(X_new).argmax(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(X_new[i],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(class_names[y_pred[i]])</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>
<img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_23_0.png" class="" alt="png">
<h1 id="使用顺序API构建回归MLP"><a href="#使用顺序API构建回归MLP" class="headerlink" title="使用顺序API构建回归MLP"></a>使用顺序API构建回归MLP</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line"></span><br><span class="line">X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=<span class="number">42</span>)</span><br><span class="line">X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train = scaler.fit_transform(X_train)</span><br><span class="line">X_valid = scaler.transform(X_valid)</span><br><span class="line">X_test = scaler.transform(X_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">30</span>, activation=<span class="string">&quot;relu&quot;</span>, input_shape=X_train.shape[<span class="number">1</span>:]),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&quot;mean_squared_error&quot;</span>, optimizer=keras.optimizers.SGD(lr=<span class="number">1e-3</span>))</span><br><span class="line">history = model.fit(X_train, y_train, epochs=<span class="number">20</span>, validation_data=(X_valid, y_valid))</span><br><span class="line">mse_test = model.evaluate(X_test, y_test)</span><br><span class="line">X_new = X_test[:<span class="number">3</span>]</span><br><span class="line">y_pred = model.predict(X_new)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 2s 6ms/step - loss: 2.6348 - val_loss: 1.4654
Epoch 2/20
363/363 [==============================] - 2s 5ms/step - loss: 0.8950 - val_loss: 0.8080
Epoch 3/20
363/363 [==============================] - 2s 5ms/step - loss: 0.7566 - val_loss: 0.6868
Epoch 4/20
363/363 [==============================] - 2s 5ms/step - loss: 0.7088 - val_loss: 0.7151
Epoch 5/20
363/363 [==============================] - 2s 4ms/step - loss: 0.6756 - val_loss: 0.6320
Epoch 6/20
363/363 [==============================] - 1s 4ms/step - loss: 0.6457 - val_loss: 0.6111
Epoch 7/20
363/363 [==============================] - 1s 4ms/step - loss: 0.6187 - val_loss: 0.5899
Epoch 8/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5930 - val_loss: 0.6116
Epoch 9/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5697 - val_loss: 0.6095
Epoch 10/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5487 - val_loss: 0.5161
Epoch 11/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5286 - val_loss: 0.4910
Epoch 12/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5115 - val_loss: 0.4832
Epoch 13/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4972 - val_loss: 0.4574
Epoch 14/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4849 - val_loss: 0.4465
Epoch 15/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4748 - val_loss: 0.4355
Epoch 16/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4662 - val_loss: 0.4291
Epoch 17/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4587 - val_loss: 0.4225
Epoch 18/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4524 - val_loss: 0.4190
Epoch 19/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4179
Epoch 20/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4419 - val_loss: 0.4159
162/162 [==============================] - 0s 2ms/step - loss: 0.4366
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(pd.DataFrame(history.history))</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.gca().set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<pre><code>(0.0, 1.0)
</code></pre><img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_27_1.png" class="" alt="png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.6820665],
       [1.432928 ],
       [3.2171566]], dtype=float32)
</code></pre><h1 id="使用函数式API构建复杂模型"><a href="#使用函数式API构建复杂模型" class="headerlink" title="使用函数式API构建复杂模型"></a>使用函数式API构建复杂模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">input_ = keras.layers.Input(shape=X_train.shape[<span class="number">1</span>:])</span><br><span class="line">hidden1 = keras.layers.Dense(<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(input_)</span><br><span class="line">hidden2 = keras.layers.Dense(<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(hidden1)</span><br><span class="line">concat = keras.layers.Concatenate()([input_,hidden2])</span><br><span class="line">output = keras.layers.Dense(<span class="number">1</span>)(concat)</span><br><span class="line">model = keras.Model(inputs=input_,outputs=output)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 8)]          0                                            
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 30)           270         input_2[0][0]                    
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38)           0           input_2[0][0]                    
                                                                 dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1)            39          concatenate_1[0][0]              
==================================================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model,show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_32_0.png" class="" alt="png">
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">input_A = keras.layers.Input(shape=[<span class="number">5</span>],name=<span class="string">&#x27;wide_input&#x27;</span>)</span><br><span class="line">input_B = keras.layers.Input(shape=[<span class="number">6</span>],name=<span class="string">&#x27;deep_input&#x27;</span>)</span><br><span class="line">hidden1 = keras.layers.Dense(<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(input_B)</span><br><span class="line">hidden2 = keras.layers.Dense(<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(hidden1)</span><br><span class="line">concat = keras.layers.Concatenate()([input_A,hidden2])</span><br><span class="line">output = keras.layers.Dense(<span class="number">1</span>,name=<span class="string">&#x27;output&#x27;</span>)(concat)</span><br><span class="line">model = keras.Model(inputs=[input_A,input_B],outputs=[output])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
deep_input (InputLayer)         [(None, 6)]          0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 30)           210         deep_input[0][0]                 
__________________________________________________________________________________________________
wide_input (InputLayer)         [(None, 5)]          0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 35)           0           wide_input[0][0]                 
                                                                 dense_1[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 1)            36          concatenate[0][0]                
==================================================================================================
Total params: 1,176
Trainable params: 1,176
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model,show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_36_0.png" class="" alt="png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=keras.optimizers.SGD(learning_rate=<span class="number">0.001</span>))</span><br></pre></td></tr></table></figure>
<p>注意：在创建模型时，我们制定了多个输入，我们在<code>fit</code>时就应该传入多个输入，在<code>predict</code>,<code>evaluate</code>时都应该有多个输入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train_A, X_train_B = X_train[:,:<span class="number">5</span>], X_train[:,<span class="number">2</span>:]</span><br><span class="line">X_valid_A, X_valid_B = X_valid[:,:<span class="number">5</span>], X_valid[:,<span class="number">2</span>:]</span><br><span class="line">X_test_A, X_test_B = X_test[:,:<span class="number">5</span>], X_test[:,<span class="number">2</span>:]</span><br><span class="line">X_new_A, X_new_B = X_test_A[:<span class="number">3</span>], X_test_B[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit((X_train_A,X_train_B),y_train,validation_data=((X_valid_A,X_valid_B),y_valid),epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 2s 4ms/step - loss: 2.6025 - val_loss: 5.7793
Epoch 2/20
363/363 [==============================] - 1s 4ms/step - loss: 0.8397 - val_loss: 2.4269
Epoch 3/20
363/363 [==============================] - 1s 4ms/step - loss: 0.6759 - val_loss: 1.3355
Epoch 4/20
363/363 [==============================] - 1s 3ms/step - loss: 0.6015 - val_loss: 0.9239
Epoch 5/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5522 - val_loss: 0.6919
Epoch 6/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5167 - val_loss: 0.5866
Epoch 7/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4893 - val_loss: 0.5162
Epoch 8/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4697 - val_loss: 0.4804
Epoch 9/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4546 - val_loss: 0.4506
Epoch 10/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4439 - val_loss: 0.4349
Epoch 11/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4360 - val_loss: 0.4267
Epoch 12/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4299 - val_loss: 0.4200
Epoch 13/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4259 - val_loss: 0.4198
Epoch 14/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4217 - val_loss: 0.4181
Epoch 15/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4144
Epoch 16/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4168 - val_loss: 0.4156
Epoch 17/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4147 - val_loss: 0.4136
Epoch 18/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4127 - val_loss: 0.4101
Epoch 19/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.4070
Epoch 20/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4078
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate((X_test_A,X_test_B),y_test)</span><br></pre></td></tr></table></figure>
<pre><code>162/162 [==============================] - 0s 2ms/step - loss: 0.4078





0.40784752368927
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.predict((X_new_A,X_new_B))</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.5327476],
       [1.9329988],
       [3.3600936]], dtype=float32)
</code></pre><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">input_A = keras.layers.Input(shape=[<span class="number">5</span>],name=<span class="string">&#x27;wide_input&#x27;</span>)</span><br><span class="line">input_B = keras.layers.Input(shape=[<span class="number">6</span>],name=<span class="string">&#x27;deep_input&#x27;</span>)</span><br><span class="line">hidden1 = keras.layers.Dense(<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(input_B)</span><br><span class="line">hidden2 = keras.layers.Dense(<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>)(hidden1)</span><br><span class="line">concat = keras.layers.Concatenate()([input_A,hidden2])</span><br><span class="line">output1 = keras.layers.Dense(<span class="number">1</span>,name=<span class="string">&#x27;output&#x27;</span>)(concat)</span><br><span class="line">output2 = keras.layers.Dense(<span class="number">1</span>,name=<span class="string">&#x27;aux&#x27;</span>)(hidden2)</span><br><span class="line">model = keras.Model(inputs=[input_A,input_B],outputs=[output1,output2])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
deep_input (InputLayer)         [(None, 6)]          0                                            
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 30)           210         deep_input[0][0]                 
__________________________________________________________________________________________________
wide_input (InputLayer)         [(None, 5)]          0                                            
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 35)           0           wide_input[0][0]                 
                                                                 dense_3[0][0]                    
__________________________________________________________________________________________________
output (Dense)                  (None, 1)            36          concatenate_1[0][0]              
__________________________________________________________________________________________________
aux (Dense)                     (None, 1)            31          dense_3[0][0]                    
==================================================================================================
Total params: 1,207
Trainable params: 1,207
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.utils.plot_model(model,show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src="/2021/08/21/%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_46_0.png" class="" alt="png">
<p>注意：每个输出都要有自己的损失函数，所以当我们编译模型时应该传递一系列的损失（如果传递单个损失，则默认所有输出使用相同的损失）。</p>
<p>默认情况下，Keras计算所有这些损失，并简单的相加得到最终的训练损失；而我们关注的是主要输出，所以要给主要输出更大的权重，我们可以通过设置参数<code>loss_weights</code>来指定不同损失的权重。除此之外，我们<code>fit</code>,<code>evaluate</code>时也要传入多个用于验证的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=[<span class="string">&#x27;mse&#x27;</span>,<span class="string">&#x27;mse&#x27;</span>],loss_weights=[<span class="number">0.9</span>,<span class="number">0.1</span>],optimizer=<span class="string">&#x27;sgd&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit([X_train_A,X_train_B],[y_train,y_train],epochs=<span class="number">20</span>,validation_data=([X_valid_A,X_valid_B],[y_valid,y_valid]))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 2s 6ms/step - loss: 0.5364 - output_loss: 0.4733 - aux_loss: 1.1042 - val_loss: 2.4807 - val_output_loss: 2.6077 - val_aux_loss: 1.3375
Epoch 2/20
363/363 [==============================] - 2s 5ms/step - loss: 0.5027 - output_loss: 0.4567 - aux_loss: 0.9175 - val_loss: 1.3039 - val_output_loss: 1.3301 - val_aux_loss: 1.0683
Epoch 3/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4725 - output_loss: 0.4361 - aux_loss: 0.8008 - val_loss: 0.9919 - val_output_loss: 0.9801 - val_aux_loss: 1.0980
Epoch 4/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4479 - output_loss: 0.4186 - aux_loss: 0.7117 - val_loss: 0.4309 - val_output_loss: 0.4022 - val_aux_loss: 0.6895
Epoch 5/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4334 - output_loss: 0.4089 - aux_loss: 0.6546 - val_loss: 0.4091 - val_output_loss: 0.3853 - val_aux_loss: 0.6233
Epoch 6/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4208 - output_loss: 0.3989 - aux_loss: 0.6178 - val_loss: 0.4338 - val_output_loss: 0.4149 - val_aux_loss: 0.6042
Epoch 7/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4143 - output_loss: 0.3942 - aux_loss: 0.5945 - val_loss: 0.4099 - val_output_loss: 0.3919 - val_aux_loss: 0.5717
Epoch 8/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4081 - output_loss: 0.3895 - aux_loss: 0.5754 - val_loss: 0.3863 - val_output_loss: 0.3680 - val_aux_loss: 0.5504
Epoch 9/20
363/363 [==============================] - 2s 5ms/step - loss: 0.4041 - output_loss: 0.3867 - aux_loss: 0.5606 - val_loss: 0.3876 - val_output_loss: 0.3707 - val_aux_loss: 0.5395
Epoch 10/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3987 - output_loss: 0.3821 - aux_loss: 0.5485 - val_loss: 0.3737 - val_output_loss: 0.3570 - val_aux_loss: 0.5239
Epoch 11/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3933 - output_loss: 0.3776 - aux_loss: 0.5348 - val_loss: 0.3769 - val_output_loss: 0.3604 - val_aux_loss: 0.5250
Epoch 12/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3951 - output_loss: 0.3802 - aux_loss: 0.5291 - val_loss: 0.3697 - val_output_loss: 0.3540 - val_aux_loss: 0.5103
Epoch 13/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3882 - output_loss: 0.3738 - aux_loss: 0.5178 - val_loss: 0.3646 - val_output_loss: 0.3488 - val_aux_loss: 0.5064
Epoch 14/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3843 - output_loss: 0.3702 - aux_loss: 0.5115 - val_loss: 0.3543 - val_output_loss: 0.3388 - val_aux_loss: 0.4932
Epoch 15/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3813 - output_loss: 0.3680 - aux_loss: 0.5011 - val_loss: 0.3764 - val_output_loss: 0.3620 - val_aux_loss: 0.5061
Epoch 16/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3886 - output_loss: 0.3752 - aux_loss: 0.5085 - val_loss: 0.6404 - val_output_loss: 0.6423 - val_aux_loss: 0.6231
Epoch 17/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3806 - output_loss: 0.3679 - aux_loss: 0.4952 - val_loss: 0.3480 - val_output_loss: 0.3344 - val_aux_loss: 0.4705
Epoch 18/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3703 - output_loss: 0.3575 - aux_loss: 0.4855 - val_loss: 0.3608 - val_output_loss: 0.3481 - val_aux_loss: 0.4753
Epoch 19/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3666 - output_loss: 0.3543 - aux_loss: 0.4766 - val_loss: 0.3572 - val_output_loss: 0.3452 - val_aux_loss: 0.4650
Epoch 20/20
363/363 [==============================] - 2s 5ms/step - loss: 0.3699 - output_loss: 0.3584 - aux_loss: 0.4740 - val_loss: 0.3714 - val_output_loss: 0.3610 - val_aux_loss: 0.4657
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">total_loss, main_loss, aux_loss = model.evaluate([X_test_A,X_test_B],[y_test,y_test])</span><br><span class="line">y_pred_main, y_aux = model.predict([X_new_A,X_new_B])</span><br></pre></td></tr></table></figure>
<pre><code>162/162 [==============================] - 0s 3ms/step - loss: 0.3888 - output_loss: 0.3806 - aux_loss: 0.4621
</code></pre><h1 id="使用子类API构建动态模型"><a href="#使用子类API构建动态模型" class="headerlink" title="使用子类API构建动态模型"></a>使用子类API构建动态模型</h1><p>通过对<code>keras.Model</code>继承，在构造函数中创建所需要的层，再在<code>call</code>方法中执行所需的计算即可。但这样Keras无法对其进行检查。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myModel</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,units=<span class="number">30</span>,activation=<span class="string">&#x27;relu&#x27;</span>,**kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        self.hidden1 = keras.layers.Dense(units,activation=activation)</span><br><span class="line">        self.hidden2 = keras.layers.Dense(units,activation=activation)</span><br><span class="line">        self.main_output = keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line">        self.aux = keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self,inputs</span>):</span></span><br><span class="line">        input_A, input_B = inputs</span><br><span class="line">        hidden1 = self.hidden1(input_B)</span><br><span class="line">        hidden2 = self.hidden2(hidden1)</span><br><span class="line">        concat = keras.layers.concatenate([input_A,hidden2])</span><br><span class="line">        aux = self.aux(hidden2)</span><br><span class="line">        main_output = self.main_output(concat)</span><br><span class="line">        <span class="keyword">return</span> main_output, aux</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = myModel()</span><br></pre></td></tr></table></figure>
<h1 id="使用回调函数"><a href="#使用回调函数" class="headerlink" title="使用回调函数"></a>使用回调函数</h1><p><code>fit()</code>方法接收一个callbacks参数，该参数可以指定Keras在训练开始和结束时（或是处理每个批量之前和之后）将调用对象列表。</p>
<p>下面介绍：ModelCheckpoint回调，定期保存模型的检查点；EarlyStopping回调，多个轮次在验证集上没有进展，模型训练就会中断并回滚到最佳模型。</p>
<p>我们也可以通过继承<code>keras.callbacks.Callback</code>，重写其中的方法来自定义自己的回调函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_cb = keras.callbacks.ModelCheckpoint(<span class="string">&#x27;my_model.h5&#x27;</span>,save_best_only=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=keras.optimizers.SGD(learning_rate=<span class="number">0.001</span>))</span><br><span class="line">history = model.fit(X_train,y_train,epochs=<span class="number">20</span>,validation_data=(X_valid,y_valid),callbacks=[checkpoint_cb])</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 1s 4ms/step - loss: 2.1240 - val_loss: 0.7047
Epoch 2/20
363/363 [==============================] - 1s 4ms/step - loss: 0.6714 - val_loss: 0.6753
Epoch 3/20
363/363 [==============================] - 1s 4ms/step - loss: 0.6299 - val_loss: 0.5984
Epoch 4/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5988 - val_loss: 0.5573
Epoch 5/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5749 - val_loss: 0.5342
Epoch 6/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5565 - val_loss: 0.5197
Epoch 7/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5413 - val_loss: 0.6011
Epoch 8/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5266 - val_loss: 0.4995
Epoch 9/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5164 - val_loss: 0.5106
Epoch 10/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5055 - val_loss: 0.4727
Epoch 11/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4972 - val_loss: 0.5377
Epoch 12/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4884 - val_loss: 0.5494
Epoch 13/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4810 - val_loss: 0.5290
Epoch 14/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4738 - val_loss: 0.4608
Epoch 15/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4683 - val_loss: 0.4647
Epoch 16/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4619 - val_loss: 0.4790
Epoch 17/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4569 - val_loss: 0.4285
Epoch 18/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4517 - val_loss: 0.4691
Epoch 19/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4460 - val_loss: 0.4570
Epoch 20/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4418 - val_loss: 0.4153
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">earlystop = keras.callbacks.EarlyStopping(patience=<span class="number">10</span>,restore_best_weights=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=<span class="string">&#x27;sgd&#x27;</span>)</span><br><span class="line">history = model.fit(X_train,y_train,epochs=<span class="number">20</span>,validation_data=(X_valid,y_valid),callbacks=[checkpoint_cb,earlystop])</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 2s 4ms/step - loss: 0.4373 - val_loss: 0.7789
Epoch 2/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4349 - val_loss: 3.3366
Epoch 3/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 11.5161
Epoch 4/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4472 - val_loss: 5.0992
Epoch 5/20
363/363 [==============================] - 1s 3ms/step - loss: 0.3935 - val_loss: 24.5138
Epoch 6/20
363/363 [==============================] - 1s 4ms/step - loss: 0.7370 - val_loss: 38.8524
Epoch 7/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5221 - val_loss: 368.9537
Epoch 8/20
363/363 [==============================] - 1s 4ms/step - loss: 0.6238 - val_loss: 80.9212
Epoch 9/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5975 - val_loss: 414.6273
Epoch 10/20
363/363 [==============================] - 1s 3ms/step - loss: 0.7681 - val_loss: 190.2743
Epoch 11/20
363/363 [==============================] - 1s 3ms/step - loss: 0.7865 - val_loss: 154.1239
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myCallback</span>(<span class="params">keras.callbacks.Callback</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self,epoch,logs</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\nval/train:&#123;:.2&#125;&#x27;</span>.<span class="built_in">format</span>(logs[<span class="string">&#x27;val_loss&#x27;</span>]/logs[<span class="string">&#x27;loss&#x27;</span>]))</span><br><span class="line">my_cb = myCallback()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=keras.optimizers.SGD(learning_rate=<span class="number">0.001</span>))</span><br><span class="line">history = model.fit(X_train,y_train,epochs=<span class="number">20</span>,validation_data=(X_valid,y_valid),callbacks=[checkpoint_cb,my_cb])</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 2s 4ms/step - loss: 1.8173 - val_loss: 4.5359

val/train:2.5
Epoch 2/20
363/363 [==============================] - 2s 4ms/step - loss: 0.7135 - val_loss: 1.6776

val/train:2.4
Epoch 3/20
363/363 [==============================] - 1s 3ms/step - loss: 0.6339 - val_loss: 0.6325

val/train:1.0
Epoch 4/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5837 - val_loss: 0.5607

val/train:0.96
Epoch 5/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5529 - val_loss: 0.5251

val/train:0.95
Epoch 6/20
363/363 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5709

val/train:1.1
Epoch 7/20
363/363 [==============================] - 1s 4ms/step - loss: 0.5105 - val_loss: 0.4771

val/train:0.93
Epoch 8/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4933 - val_loss: 0.4701

val/train:0.95
Epoch 9/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4797 - val_loss: 0.4542

val/train:0.95
Epoch 10/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4682 - val_loss: 0.4373

val/train:0.93
Epoch 11/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4588 - val_loss: 0.4422

val/train:0.96
Epoch 12/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4514 - val_loss: 0.4256

val/train:0.94
Epoch 13/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4444 - val_loss: 0.4224

val/train:0.95
Epoch 14/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4384 - val_loss: 0.4104

val/train:0.94
Epoch 15/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4329 - val_loss: 0.4071

val/train:0.94
Epoch 16/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4281 - val_loss: 0.4084

val/train:0.95
Epoch 17/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4234 - val_loss: 0.3962

val/train:0.94
Epoch 18/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.3929

val/train:0.94
Epoch 19/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.3929

val/train:0.94
Epoch 20/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4127 - val_loss: 0.3911

val/train:0.95
</code></pre><h1 id="微调神经网络超参数"><a href="#微调神经网络超参数" class="headerlink" title="微调神经网络超参数"></a>微调神经网络超参数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>(<span class="params">n_hidden=<span class="number">1</span>,n_neurons=<span class="number">30</span>,lr=<span class="number">0.003</span>,input_shape=[<span class="number">8</span>]</span>):</span></span><br><span class="line">    model = keras.models.Sequential()</span><br><span class="line">    model.add(keras.layers.InputLayer(input_shape=input_shape))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_hidden):</span><br><span class="line">        model.add(keras.layers.Dense(n_neurons,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(keras.layers.Dense(<span class="number">1</span>))</span><br><span class="line">    optimizer = keras.optimizers.SGD(learning_rate=lr)</span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=optimizer)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> reciprocal</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> param = &#123;<span class="string">&#x27;n_hidden&#x27;</span>:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">          <span class="string">&#x27;n_neurons&#x27;</span>:np.arange(<span class="number">1</span>,<span class="number">100</span>),</span><br><span class="line">          <span class="string">&#x27;lr&#x27;</span>:reciprocal(<span class="number">3e-4</span>,<span class="number">3e-2</span>)&#125;</span><br><span class="line">rnd_search = RandomizedSearchCV(keras_reg,param,n_iter=<span class="number">10</span>,cv=<span class="number">3</span>)</span><br><span class="line">rnd_search.fit(X_train,y_train,epochs=<span class="number">100</span>,validation_data=(X_valid,y_valid),</span><br><span class="line">               callbacks=keras.callbacks.EarlyStopping(patience=<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/100
242/242 [==============================] - 5s 7ms/step - loss: 3.5815 - val_loss: 2.2888
Epoch 2/100
242/242 [==============================] - 1s 6ms/step - loss: 1.7560 - val_loss: 2.5086
Epoch 3/100
242/242 [==============================] - 1s 6ms/step - loss: 1.2191 - val_loss: 1.9225
Epoch 4/100
242/242 [==============================] - 2s 6ms/step - loss: 0.9811 - val_loss: 0.9753
Epoch 5/100
242/242 [==============================] - 2s 8ms/step - loss: 0.8616 - val_loss: 0.8079
Epoch 6/100
242/242 [==============================] - 2s 8ms/step - loss: 0.8030 - val_loss: 0.7575
Epoch 7/100
242/242 [==============================] - 2s 8ms/step - loss: 0.7713 - val_loss: 0.7350
Epoch 8/100
242/242 [==============================] - 2s 7ms/step - loss: 0.7513 - val_loss: 0.7270
Epoch 9/100
242/242 [==============================] - 2s 6ms/step - loss: 0.7336 - val_loss: 0.7480
Epoch 10/100
242/242 [==============================] - 2s 8ms/step - loss: 0.7184 - val_loss: 0.6900

......

Epoch 43/100
363/363 [==============================] - 1s 4ms/step - loss: 0.2850 - val_loss: 0.3304
Epoch 44/100
363/363 [==============================] - 1s 4ms/step - loss: 0.2924 - val_loss: 0.3627
Epoch 45/100
363/363 [==============================] - 1s 4ms/step - loss: 0.2917 - val_loss: 0.2973
Epoch 46/100
363/363 [==============================] - 2s 4ms/step - loss: 0.2852 - val_loss: 0.3063
Epoch 47/100
363/363 [==============================] - 1s 4ms/step - loss: 0.2834 - val_loss: 0.2980





RandomizedSearchCV(cv=3,
                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000204C9FA0700&gt;,
                   param_distributions=&#123;&#39;lr&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x00000204CA37D970&gt;,
                    &#39;n_hidden&#39;: [0, 1, 2, 3],
                    &#39;n_neurons&#39;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
                                       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,
                                       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,
                                       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
                                       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,
                                       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])&#125;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(rnd_search.best_params_)</span><br><span class="line"><span class="built_in">print</span>(rnd_search.best_score_)</span><br><span class="line">model = rnd_search.best_estimator_.model</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;lr&#39;: 0.006537702460946492, &#39;n_hidden&#39;: 2, &#39;n_neurons&#39;: 97&#125;
-0.3313012421131134
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.predict(X_test[:<span class="number">8</span>]))</span><br><span class="line"><span class="built_in">print</span>(y_test[:<span class="number">8</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[0.4486066]
 [1.2853019]
 [4.6888404]
 [2.4607358]
 [3.0793304]
 [1.7062786]
 [2.475378 ]
 [1.6391015]]
[0.477   0.458   5.00001 2.186   2.78    1.587   1.982   1.575  ]
</code></pre><h1 id="使用Tensorboard可视化"><a href="#使用Tensorboard可视化" class="headerlink" title="使用Tensorboard可视化"></a>使用Tensorboard可视化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dir</span>():</span></span><br><span class="line">    <span class="keyword">import</span> os</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    root = os.path.join(os.curdir,<span class="string">&#x27;my_logs&#x27;</span>)</span><br><span class="line">    now = time.strftime(<span class="string">&#x27;run_%Y_%m_%d-%H_%M_%S&#x27;</span>)</span><br><span class="line">    log_dir = os.path.join(root,now)</span><br><span class="line">    <span class="keyword">return</span> log_dir</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">run_dir = get_dir()</span><br><span class="line">run_dir</span><br></pre></td></tr></table></figure>
<pre><code>&#39;.\\my_logs\\run_2021_08_19-08_32_56&#39;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensorboard_cb = keras.callbacks.TensorBoard(run_dir)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=keras.optimizers.SGD(learning_rate=<span class="number">0.001</span>))</span><br><span class="line">model.fit(X_train,y_train,epochs=<span class="number">20</span>,validation_data=(X_valid,y_valid),callbacks=[tensorboard_cb])</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
363/363 [==============================] - 4s 6ms/step - loss: 1.5561 - val_loss: 1.5187
Epoch 2/20
363/363 [==============================] - 2s 6ms/step - loss: 0.6865 - val_loss: 0.6418
Epoch 3/20
363/363 [==============================] - 2s 6ms/step - loss: 0.6270 - val_loss: 0.6595
Epoch 4/20
363/363 [==============================] - 2s 6ms/step - loss: 0.5937 - val_loss: 0.5843
Epoch 5/20
363/363 [==============================] - 2s 6ms/step - loss: 0.5651 - val_loss: 0.5278
Epoch 6/20
363/363 [==============================] - 2s 6ms/step - loss: 0.5430 - val_loss: 0.5624
Epoch 7/20
363/363 [==============================] - 2s 5ms/step - loss: 0.5248 - val_loss: 0.5022
Epoch 8/20
363/363 [==============================] - 2s 4ms/step - loss: 0.5094 - val_loss: 0.4765
Epoch 9/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4959 - val_loss: 0.4660
Epoch 10/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4840 - val_loss: 0.4719
Epoch 11/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4745 - val_loss: 0.4435
Epoch 12/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4662 - val_loss: 0.4403
Epoch 13/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4587 - val_loss: 0.4307
Epoch 14/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4518 - val_loss: 0.4217
Epoch 15/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4219
Epoch 16/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4410 - val_loss: 0.4171
Epoch 17/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4357 - val_loss: 0.4126
Epoch 18/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4316 - val_loss: 0.4067
Epoch 19/20
363/363 [==============================] - 1s 4ms/step - loss: 0.4276 - val_loss: 0.4016
Epoch 20/20
363/363 [==============================] - 1s 3ms/step - loss: 0.4236 - val_loss: 0.4090
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> summary</span><br><span class="line">writer = summary.create_file_writer(get_dir())</span><br><span class="line"><span class="keyword">with</span> writer.as_default():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">1000</span>+<span class="number">1</span>):</span><br><span class="line">        summary.scalar(<span class="string">&#x27;my_scalar&#x27;</span>,np.sin(i/<span class="number">10</span>),i)</span><br><span class="line">        data = (np.random.randn(<span class="number">100</span>)+<span class="number">2</span>)*i/<span class="number">1000</span></span><br><span class="line">        summary.histogram(<span class="string">&#x27;my_histogram&#x27;</span>,data,buckets=<span class="number">50</span>,step=i)</span><br><span class="line">        img = np.random.rand(<span class="number">2</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">2</span>)</span><br><span class="line">        summary.image(<span class="string">&#x27;my_img&#x27;</span>,img*i/<span class="number">1000</span>,step=i)</span><br><span class="line">        txt = [<span class="string">&#x27;step is &#x27;</span>+<span class="built_in">str</span>(i),<span class="string">&#x27;the square is &#x27;</span>+<span class="built_in">str</span>(i**<span class="number">2</span>)]</span><br><span class="line">        summary.text(<span class="string">&#x27;my_text&#x27;</span>,txt,step=i)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Keras/" rel="tag"># Keras</a>
              <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"># 神经网络</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/08/21/%E5%9B%9E%E5%BD%92%E5%A4%A7%E5%AE%B6%E6%97%8F/" rel="prev" title="回归大家族">
      <i class="fa fa-chevron-left"></i> 回归大家族
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%A1%BA%E5%BA%8FAPI%E6%9E%84%E5%BB%BA%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">1.</span> <span class="nav-text">使用顺序API构建图像分类器</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%A1%BA%E5%BA%8FAPI%E6%9E%84%E5%BB%BA%E5%9B%9E%E5%BD%92MLP"><span class="nav-number">2.</span> <span class="nav-text">使用顺序API构建回归MLP</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0%E5%BC%8FAPI%E6%9E%84%E5%BB%BA%E5%A4%8D%E6%9D%82%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">使用函数式API构建复杂模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%AD%90%E7%B1%BBAPI%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.</span> <span class="nav-text">使用子类API构建动态模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0"><span class="nav-number">5.</span> <span class="nav-text">使用回调函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B6%85%E5%8F%82%E6%95%B0"><span class="nav-number">6.</span> <span class="nav-text">微调神经网络超参数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Tensorboard%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">7.</span> <span class="nav-text">使用Tensorboard可视化</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ellen DeGeneres</p>
  <div class="site-description" itemprop="description">major in Nuclear Engineering and AI.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ellen DeGeneres</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
